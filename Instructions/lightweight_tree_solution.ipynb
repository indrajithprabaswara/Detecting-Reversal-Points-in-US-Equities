{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detecting Reversal Points in US Equities (Lightweight Local Pipeline)\n",
        "\n",
        "This notebook demonstrates a fully local, dependency-free workflow for the competition.\n",
        "The environment lacks pandas/NumPy/LightGBM, so the solution relies on Python's standard library\n",
        "for data loading, exploratory analysis, and a scratch-built decision-tree classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train path: Dataset/competition_data/train.csv\n",
            "Test path: Dataset/competition_data/test.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from collections import Counter, defaultdict\n",
        "from statistics import mean, median\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path('Dataset/competition_data')\n",
        "train_path = DATA_DIR / 'train.csv'\n",
        "test_path = DATA_DIR / 'test.csv'\n",
        "print('Train path:', train_path)\n",
        "print('Test path:', test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution: Counter({'None': 1820, 'H': 58, 'L': 54})\n",
            "None: 1820 samples (94.15% of training data)\n",
            "H: 58 samples (3.00% of training data)\n",
            "L: 54 samples (2.79% of training data)\n"
          ]
        }
      ],
      "source": [
        "label_map = {'': 'None', 'HH': 'H', 'LH': 'H', 'HL': 'L', 'LL': 'L'}\n",
        "class_counts = Counter()\n",
        "with open(train_path) as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    cls_idx = header.index('class_label')\n",
        "    for row in reader:\n",
        "        class_counts[label_map.get(row[cls_idx], 'None')] += 1\n",
        "print('Class distribution:', class_counts)\n",
        "total = sum(class_counts.values())\n",
        "for label in ['None', 'H', 'L']:\n",
        "    share = 100 * class_counts[label] / total\n",
        "    print(f\"{label}: {class_counts[label]} samples ({share:.2f}% of training data)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "momentum: min=96.088 | mean=99.992 | median=99.985 | p25=99.572 | p75=100.445 | max=102.465\n",
            "sm_momentum: min=97.709 | mean=99.981 | median=99.965 | p25=99.519 | p75=100.434 | max=102.842\n",
            "ratio: min=95.328 | mean=100.003 | median=99.982 | p25=99.402 | p75=100.634 | max=103.870\n",
            "sm_ratio: min=98.494 | mean=99.969 | median=99.981 | p25=99.640 | p75=100.265 | max=101.501\n"
          ]
        }
      ],
      "source": [
        "numeric_cols = ['momentum', 'sm_momentum', 'ratio', 'sm_ratio']\n",
        "values = {col: [] for col in numeric_cols}\n",
        "with open(train_path) as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    idx = {col: header.index(col) for col in numeric_cols}\n",
        "    for row in reader:\n",
        "        for col in numeric_cols:\n",
        "            values[col].append(float(row[idx[col]]))\n",
        "for col in numeric_cols:\n",
        "    data = sorted(values[col])\n",
        "    count = len(data)\n",
        "    p25 = data[int(0.25 * (count - 1))]\n",
        "    p50 = data[int(0.50 * (count - 1))]\n",
        "    p75 = data[int(0.75 * (count - 1))]\n",
        "    col_mean = sum(data) / count\n",
        "    print(f\"{col}: min={data[0]:.3f} | mean={col_mean:.3f} | median={p50:.3f} | p25={p25:.3f} | p75={p75:.3f} | max={data[-1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 accuracy: 0.9406\n",
            "Fold 2 accuracy: 0.9354\n",
            "Fold 3 accuracy: 0.9406\n",
            "Fold 4 accuracy: 0.9404\n",
            "Fold 5 accuracy: 0.9455\n",
            "Average accuracy: 0.9404813041853648\n"
          ]
        }
      ],
      "source": [
        "from math import inf\n",
        "\n",
        "def load_features(path):\n",
        "    feats, labels = [], []\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f)\n",
        "        header = next(reader)\n",
        "        idx = {col: header.index(col) for col in ['momentum', 'sm_momentum', 'ratio', 'sm_ratio']}\n",
        "        cls_idx = header.index('class_label')\n",
        "        for row in reader:\n",
        "            feats.append([float(row[idx[col]]) for col in ['momentum', 'sm_momentum', 'ratio', 'sm_ratio']])\n",
        "            labels.append(label_map.get(row[cls_idx], 0))\n",
        "    return feats, labels\n",
        "\n",
        "features, labels = load_features(train_path)\n",
        "num_features = len(features[0])\n",
        "\n",
        "class Node:\n",
        "    __slots__ = ('feature','threshold','left','right','label')\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, label=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.label = label\n",
        "\n",
        "def gini(counts):\n",
        "    total = sum(counts)\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "    impurity = 1.0\n",
        "    for count in counts:\n",
        "        prob = count / total\n",
        "        impurity -= prob * prob\n",
        "    return impurity\n",
        "\n",
        "def build_tree(indices, depth, max_depth, min_samples):\n",
        "    counts = [0, 0, 0]\n",
        "    for idx in indices:\n",
        "        counts[labels[idx]] += 1\n",
        "    majority = max(range(3), key=lambda c: counts[c])\n",
        "    if depth >= max_depth or len(indices) <= min_samples or max(counts) == len(indices):\n",
        "        return Node(label=majority)\n",
        "    current = gini(counts)\n",
        "    best_gain = -inf\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    total = len(indices)\n",
        "    for feature_idx in range(num_features):\n",
        "        sorted_idx = sorted(indices, key=lambda i: features[i][feature_idx])\n",
        "        left_counts = [0, 0, 0]\n",
        "        right_counts = counts.copy()\n",
        "        for i in range(len(sorted_idx) - 1):\n",
        "            idx = sorted_idx[i]\n",
        "            lbl = labels[idx]\n",
        "            left_counts[lbl] += 1\n",
        "            right_counts[lbl] -= 1\n",
        "            value = features[idx][feature_idx]\n",
        "            next_value = features[sorted_idx[i + 1]][feature_idx]\n",
        "            if value == next_value:\n",
        "                continue\n",
        "            threshold = (value + next_value) / 2\n",
        "            left_total = i + 1\n",
        "            right_total = total - left_total\n",
        "            if left_total < min_samples or right_total < min_samples:\n",
        "                continue\n",
        "            impurity = (left_total / total) * gini(left_counts) + (right_total / total) * gini(right_counts)\n",
        "            gain = current - impurity\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_feature = feature_idx\n",
        "                best_threshold = threshold\n",
        "    if best_feature is None:\n",
        "        return Node(label=majority)\n",
        "    left_indices = [i for i in indices if features[i][best_feature] <= best_threshold]\n",
        "    right_indices = [i for i in indices if features[i][best_feature] > best_threshold]\n",
        "    left_node = build_tree(left_indices, depth + 1, max_depth, min_samples)\n",
        "    right_node = build_tree(right_indices, depth + 1, max_depth, min_samples)\n",
        "    return Node(feature=best_feature, threshold=best_threshold, left=left_node, right=right_node)\n",
        "\n",
        "def predict(node, sample):\n",
        "    while node.feature is not None:\n",
        "        if sample[node.feature] <= node.threshold:\n",
        "            node = node.left\n",
        "        else:\n",
        "            node = node.right\n",
        "    return node.label\n",
        "\n",
        "# Stratified 5-fold evaluation\n",
        "indices = list(range(len(features)))\n",
        "per_class = defaultdict(list)\n",
        "for idx, label in enumerate(labels):\n",
        "    per_class[label].append(idx)\n",
        "folds = [[] for _ in range(5)]\n",
        "for arr in per_class.values():\n",
        "    random.shuffle(arr)\n",
        "    for i, idx in enumerate(arr):\n",
        "        folds[i % 5].append(idx)\n",
        "\n",
        "cv_scores = []\n",
        "for fold_idx, val_idx in enumerate(folds):\n",
        "    train_idx = [i for i in indices if i not in val_idx]\n",
        "    tree = build_tree(train_idx, 0, 3, 5)\n",
        "    correct = 0\n",
        "    for idx in val_idx:\n",
        "        if predict(tree, features[idx]) == labels[idx]:\n",
        "            correct += 1\n",
        "    acc = correct / len(val_idx)\n",
        "    cv_scores.append(acc)\n",
        "    print(f\"Fold {fold_idx+1} accuracy: {acc:.4f}\")\n",
        "print('Average accuracy:', sum(cv_scores)/len(cv_scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy on full data: 0.943064182194617\n",
            "Saved submission_tree.csv with 828 rows\n",
            "Submission label distribution: {'L': 3, 'None': 825}\n"
          ]
        }
      ],
      "source": [
        "# Train final tree on full data\n",
        "full_indices = list(range(len(features)))\n",
        "final_tree = build_tree(full_indices, 0, 3, 5)\n",
        "train_correct = sum(1 for idx in full_indices if predict(final_tree, features[idx]) == labels[idx])\n",
        "print('Training accuracy on full data:', train_correct / len(features))\n",
        "\n",
        "# Generate predictions for test set\n",
        "pred_labels = []\n",
        "pred_ids = []\n",
        "with open(test_path) as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    idx = {col: header.index(col) for col in ['momentum', 'sm_momentum', 'ratio', 'sm_ratio']}\n",
        "    id_idx = header.index('id') if 'id' in header else 0\n",
        "    for row in reader:\n",
        "        sample = [float(row[idx[col]]) for col in ['momentum', 'sm_momentum', 'ratio', 'sm_ratio']]\n",
        "        label_idx = predict(final_tree, sample)\n",
        "        pred_labels.append(label_names[label_idx])\n",
        "        pred_ids.append(row[id_idx])\n",
        "\n",
        "# Write submission\n",
        "with open('submission_tree.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id', 'class_label'])\n",
        "    for idx, label in zip(pred_ids, pred_labels):\n",
        "        writer.writerow([idx, label])\n",
        "print('Saved submission_tree.csv with', len(pred_labels), 'rows')\n",
        "counts = defaultdict(int)\n",
        "for lbl in pred_labels:\n",
        "    counts[lbl] += 1\n",
        "print('Submission label distribution:', dict(counts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id,class_label\n",
            "0,None\n",
            "1,None\n",
            "2,None\n",
            "3,None\n"
          ]
        }
      ],
      "source": [
        "with open('submission_tree.csv') as f:\n",
        "    for _ in range(5):\n",
        "        print(f.readline().strip())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}